#!/usr/bin/env ansible-playbook
# vagrant machine provisioner (based on host's ansible.groups values set in Vagrantfile)
---
# TODO: Move this to the roles that setup a virtual machine
- hosts: all
  tasks:
    - file:
        path: '{{ ansible_env.HOME }}/{{ item }}'
        state: absent
      with_items: [shutdown.sh, yankring_history_v2.txt]

- hosts: kubectl #:!minikube
  # NOTE: These vars need to be accessible to the project, e.g. utils.yml -e@utils/build.yml needs the cluster_host and local_registry_port in order to tag the image to push it
  # This should go into the machine's prepd.yml config file which also has directory locations. Anything that is a machine wide configuration goes here
  # This would include machine's timezone, docker daemon config, perhaps PG installation and so on. The project could still configure this stuff, but doesn't have to
  # vars:
  #   cluster_host: node1
  #   cluster_ssh: n1
  #   local_registry_port: 30005

  tasks:
    - include_role:
        name: prepd/machine

    - name: Insert aliases
      include_role:
        name: prepd/aliases
      vars:
        aliases_marker: host-ssh
        aliases_block: |
          {{ prepd_machine.cluster.ssh }}() { ssh {{ prepd_machine.cluster.host }} $@ }

    - name: Use scp to copy minikube credentials from cluster
      include_role:
        name: prepd/k8s/kubectl
        tasks_from: remote
      vars:
        k8s_kubectl_cluster_host: '{{ prepd_machine.cluster.host }}'

    - name: Initialize helm
      command: helm init

    - name: Wait for tiller to be available
      pause:
        seconds: 30
